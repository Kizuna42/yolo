# 人物検出 AI PoC 実装計画書

## 1. プロジェクト概要

### 1.1 基本情報

- **プロジェクト名**: 人物検出 AI システム PoC（概念実証）
- **目的**: YOLOv11 を用いた人物検出の精度検証と技術確立
- **スコープ**: タイムスタンプ付き動画からの時刻指定フレーム抽出と人物検出、検出精度の評価
- **期間**: 2 週間（概念実証段階）
- **入力データ**: merged_moviefiles.mov (1280x720, 30fps, H.264, タイムスタンプ付き)

### 1.2 機能要件

- **入力**: 定点カメラの連続録画動画ファイル（タイムスタンプ付き）
- **出力**: 5 分間隔の静止画フレーム（タイムスタンプ付き）
- **処理内容**:
- [x] 動画内のタイムスタンプ OCR 認識
- [x] 指定時刻に最も近いフレーム抽出
- [x] ファイル名規則に従った保存
- [x] 抽出フレームでの人物検出

### 1.3 技術要件

- **タイムスタンプ位置**: 画面右上固定
- **時刻フォーマット**: YYYY/MM/DD HH:MM:SS
- **抽出間隔**: 5 分 ±10 秒（バッファ考慮）
- **画像品質**: 元動画と同等の解像度維持（1280x720）
- **人物検出精度**: 90%以上

### 1.4 成果物

- [x] タイムスタンプ OCR システム
- [x] 時刻指定フレーム抽出システム
- [x] 人物検出システム（YOLOv11 ベース）
- [ ] 精度評価レポート
- [ ] 処理速度ベンチマーク結果
- [ ] 技術検証ドキュメント

### 1.5 成功基準

- [ ] タイムスタンプ OCR 認識精度: 99%以上
- [x] 時刻指定フレーム抽出精度: ±10 秒以内
- [ ] 人物検出精度: 90%以上
- [ ] 処理速度: 実用的な速度（バッチ処理対応）
- [ ] False Positive 率: 10%以下
- [ ] False Negative 率: 5%以下

## 2. 技術仕様

### 2.1 入力データ仕様

- **ファイル名**: merged_moviefiles.mov
- **解像度**: 1280 x 720 (HD)
- **フレームレート**: 30fps
- **コーデック**: H.264
- **アスペクト比**: 16:9
- **ファイルサイズ**: 約 1GB
- **タイムスタンプ**: 画面右上に YYYY/MM/DD HH:MM:SS 形式で表示

### 2.2 対象環境

- **開発環境**: macOS (MacBook Pro M1 Max)
- **Python 版**: 3.8 以上
- **チップセット**: Apple M1 Max
- **メモリ**: 64GB RAM
- **ストレージ**: SSD 推奨
- **追加ソフトウェア**: FFmpeg（インストール済み）

## 3. 実装フェーズ

### フェーズ 1: 環境構築・基盤準備（2 日間）

#### 1.1 開発環境セットアップ

- [x] **Python 環境の準備**
  - [x] Python 3.8+のインストール確認
  - [x] 仮想環境の作成（venv/conda）
  - [x] 仮想環境のアクティベート
- [x] **必要ライブラリのインストール**
  - [x] ultralytics（YOLOv11）のインストール
    ```bash
    pip install ultralytics
    ```
  - [x] OpenCV のインストール
    ```bash
    pip install opencv-python opencv-python-headless
    ```
  - [x] PyTorch のインストール（Apple Silicon 対応）
    ```bash
    pip install torch torchvision torchaudio
    ```
  - [x] OCR 関連ライブラリのインストール
    ```bash
    pip install pytesseract easyocr
    brew install tesseract
    ```
  - [x] FFmpeg Python バインディング
    ```bash
    pip install ffmpeg-python
    ```
  - [x] その他必要ライブラリ
    ```bash
    pip install numpy pandas matplotlib seaborn pillow tqdm python-dateutil
    ```
  - [x] requirements.txt の作成

#### 1.2 プロジェクト構造の作成

- [x] **ディレクトリ構造の設計**
  ```
  yolo/
  ├── input/
  │   └── merged_moviefiles.mov
  ├── output/
  │   ├── frames/           # 抽出フレーム保存
  │   ├── timestamps/       # タイムスタンプ抽出結果
  │   ├── detections/       # 人物検出結果
  │   └── results/          # 最終結果・レポート
  ├── models/               # 学習済みモデル
  ├── src/
  │   ├── ocr/             # タイムスタンプOCR処理
  │   ├── extraction/      # フレーム抽出処理
  │   ├── detection/       # 人物検出処理
  │   ├── evaluation/      # 評価システム
  │   └── utils/           # ユーティリティ
  ├── config/              # 設定ファイル
  ├── tests/               # テストコード
  └── docs/                # ドキュメント
  ```
- [x] 各ディレクトリの作成
- [x] .gitignore ファイルの作成
- [x] README.md の初版作成

#### 1.3 YOLO 環境と OCR の確認

- [x] **YOLOv11 の動作確認**

  - [x] サンプル画像での検出テスト
  - [x] 事前学習モデルのダウンロード確認
  - [x] Apple M1 Max での動作確認
  - [x] 基本的な推論速度の計測

- [x] **OCR エンジンの動作確認**
  - [x] Tesseract の動作テスト
  - [x] EasyOCR の動作テスト
  - [x] 日時フォーマット認識テスト
  - [x] 精度比較・最適エンジン選定

### フェーズ 2: データ前処理・分析（3 日間）

#### 2.1 入力動画の解析とタイムスタンプ処理

- [x] **動画ファイルの基本情報取得**

  - [x] 総フレーム数の算出
  - [x] 動画の総再生時間の確認
  - [x] タイムスタンプ領域の特定（画面右上）
  - [x] データ品質の目視確認

- [x] **タイムスタンプ OCR システムの作成**

  ```python
  class TimestampOCR:
      - [x] __init__: OCR エンジン初期化、認識領域設定
      - [x] extract_timestamp_region: タイムスタンプ領域の切り出し
      - [x] preprocess_image: OCR 前処理（二値化、ノイズ除去）
      - [x] recognize_timestamp: タイムスタンプの OCR 認識
      - [x] parse_datetime: 認識結果の日時パース
      - [x] validate_timestamp: タイムスタンプの妥当性検証
  ```

- [x] **時刻指定フレーム抽出システムの作成**

  ```python
  class TimeBasedFrameExtractor:
      - [x] __init__: 動画ファイルパス、抽出間隔設定
      - [x] scan_timestamps: 全フレームのタイムスタンプスキャン
      - [x] find_target_frames: 5分間隔の目標時刻計算
      - [x] extract_closest_frame: 目標時刻に最も近いフレーム抽出
      - [x] save_frame_with_metadata: メタデータ付きフレーム保存
  ```

- [x] **初期タイムスタンプ認識テスト**
  - [x] サンプルフレームでの OCR 精度確認
  - [x] 認識エラーパターンの特定
  - [x] 前処理パラメータの調整
  - [ ] 認識精度 99%以上の達成

#### 2.2 5 分間隔フレーム抽出の実行

- [x] **5 分間隔抽出の実行**

  - [x] 動画開始時刻の特定
  - [x] 5 分間隔の目標時刻リスト生成
  - [x] 各目標時刻に対する最適フレーム検索
  - [x] ±10 秒バッファ内での最良フレーム選択

- [x] **抽出フレームの品質管理**

  - [x] 抽出フレームの解像度確認
  - [x] タイムスタンプの可読性チェック
  - [x] ファイル命名規則の実装
    ```
    例: frame_2024-01-01_14-30-00.jpg
    ```
  - [x] メタデータファイルの生成（JSON 形式）

- [x] **抽出結果の検証**
  - [x] 抽出間隔の精度確認（±10 秒以内）
  - [x] 欠損フレームの特定
  - [x] 品質異常フレームの検出
  - [x] 統計サマリーの生成

### フェーズ 3: モデル実装・検証（4 日間）

#### 3.1 YOLOv11 モデルの基本実装

- [x] **人物検出モジュールの作成**

  ```python
  class PersonDetector:
      - [x] __init__: モデル初期化、設定読み込み
      - [x] load_model: 事前学習モデルまたはカスタムモデル読み込み
      - [x] preprocess_image: 入力画像の前処理
      - [x] detect_persons: 人物検出の実行
      - [x] postprocess_results: 結果の後処理、フィルタリング
      - [x] draw_bboxes: 検出結果の可視化
  ```

- [x] **設定管理モジュール**
  ```python
  class Config:
      - [x] confidence_threshold: 信頼度閾値（デフォルト: 0.5）
      - [x] iou_threshold: IoU閾値（デフォルト: 0.45）
      - [x] image_size: 入力画像サイズ（デフォルト: 640）
      - [x] device: 実行デバイス（auto/cpu/gpu）
  ```

#### 3.2 事前学習モデルでの検証

- [x] **COCO 事前学習モデルのテスト**

  - [x] yolo11n.pt モデルでの検証
  - [ ] yolo11s.pt モデルでの検証
  - [ ] yolo11m.pt モデルでの検証
  - [ ] 各モデルの精度・速度比較（Apple M1 Max 最適化）

- [ ] **パラメータチューニング**
  - [ ] 信頼度閾値の最適化（0.3, 0.5, 0.7 で比較）
  - [ ] IoU 閾値の最適化（0.3, 0.45, 0.6 で比較）
  - [ ] 入力画像サイズの最適化（416, 640, 832 で比較）
  - [ ] バッチサイズの最適化

#### 3.3 カスタムモデルの検討

- [ ] **ファインチューニングの実装**

  ```python
  class ModelTrainer:
      - [ ] prepare_dataset: YOLOフォーマットでのデータセット準備
      - [ ] configure_training: 訓練パラメータの設定
      - [ ] train_model: モデルの訓練実行
      - [ ] validate_model: 検証データでの評価
      - [ ] save_model: 訓練済みモデルの保存
  ```

- [ ] **訓練パラメータの設定**
  - [ ] epochs: 訓練エポック数（50-100）
  - [ ] batch_size: バッチサイズ（8-16）
  - [ ] learning_rate: 学習率（0.001-0.01）
  - [ ] augmentation: データ拡張設定

### フェーズ 4: 性能評価・最適化（3 日間）

#### 4.1 精度評価システムの実装

- [ ] **評価メトリクスの実装**

  ```python
  class ModelEvaluator:
      - [ ] calculate_precision: 精度の計算
      - [ ] calculate_recall: 再現率の計算
      - [ ] calculate_f1_score: F1スコアの計算
      - [ ] calculate_ap: Average Precision計算
      - [ ] calculate_map: mean Average Precision計算
      - [ ] generate_confusion_matrix: 混同行列の生成
  ```

- [ ] **詳細評価の実行**
  - [ ] フレーム別精度の計算
  - [ ] 人数別精度の分析
  - [ ] 距離別精度の分析（カメラからの距離）
  - [ ] 照明条件別精度の分析

#### 4.2 処理速度の評価

- [ ] **ベンチマークシステムの実装**

  ```python
  class PerformanceBenchmark:
      - [ ] measure_inference_time: 推論時間の計測
      - [ ] measure_preprocessing_time: 前処理時間の計測
      - [ ] measure_postprocessing_time: 後処理時間の計測
      - [ ] calculate_fps: FPS計算
      - [ ] memory_usage_analysis: メモリ使用量分析
  ```

- [ ] **各種条件での速度計測**
  - [ ] CPU 環境での処理速度
  - [ ] GPU 環境での処理速度（利用可能な場合）
  - [ ] バッチ処理 vs 単一フレーム処理
  - [ ] 異なる解像度での処理速度

#### 4.3 結果分析・レポート作成

- [ ] **可視化システムの実装**

  ```python
  class ResultVisualizer:
      - [ ] plot_precision_recall_curve: PR曲線の描画
      - [ ] plot_confidence_distribution: 信頼度分布の描画
      - [ ] create_detection_samples: 検出結果サンプルの作成
      - [ ] generate_performance_charts: 性能チャートの生成
  ```

- [ ] **総合評価レポートの作成**
  - [ ] 精度評価結果のまとめ
  - [ ] 処理速度ベンチマーク結果
  - [ ] エラーケース分析
  - [ ] 改善提案事項

### フェーズ 5: 統合・最終検証（2 日間）

#### 5.1 エンドツーエンドシステムの構築

- [ ] **統合パイプラインの実装**

  ```python
  class TimeBasedPersonDetectionPipeline:
      - [ ] __init__: 全コンポーネントの初期化
      - [ ] process_video: 動画全体の時刻ベース処理
      - [ ] extract_timed_frames: 5分間隔フレーム抽出
      - [ ] detect_persons_in_frames: 抽出フレームでの人物検出
      - [ ] save_results: 結果の構造化保存
      - [ ] generate_report: 総合レポートの生成
  ```

- [ ] **バッチ処理システム**
  - [ ] 大容量動画の分割処理
  - [ ] 進捗表示機能（タイムスタンプ進行状況）
  - [ ] エラーハンドリング（OCR 失敗、検出失敗）
  - [ ] ログ出力機能（処理履歴、エラーログ）

#### 5.2 実動画での最終検証

- [ ] **merged_moviefiles.mov の完全処理**

  - [ ] 全体のタイムスタンプスキャン
  - [ ] 5 分間隔フレーム抽出（±10 秒精度）
  - [ ] 全抽出フレームでの人物検出
  - [ ] 処理時間とメモリ使用量の記録

- [ ] **結果の品質チェック**
  - [ ] タイムスタンプ抽出精度の検証（99%以上）
  - [ ] フレーム抽出間隔の精度確認（±10 秒以内）
  - [ ] 人物検出精度の評価（90%以上）
  - [ ] エラーケースの分析と改善提案

## 4. 技術検証項目

### 4.1 必須検証項目

- [ ] **タイムスタンプ OCR の検証**

  - [ ] 様々な照明条件での認識精度
  - [ ] ノイズ・圧縮アーティファクトへの耐性
  - [ ] 文字かすれ・ぼけへの対応
  - [ ] 認識速度の測定

- [ ] **時刻指定フレーム抽出の検証**

  - [ ] 5 分間隔の抽出精度（±10 秒以内）
  - [ ] 動画開始・終了付近での動作
  - [ ] タイムスタンプ欠損時の処理
  - [ ] 重複・スキップフレームの検出

- [ ] **人物検出精度の検証**

  - [ ] 様々な人数（1 人、複数人）での精度
  - [ ] 距離別精度（近距離、遠距離）
  - [ ] 角度別精度（正面、側面、背面）
  - [ ] 部分遮蔽時の検出性能

- [ ] **処理性能の検証**
  - [ ] Apple M1 Max での最適化効果
  - [ ] メモリ使用量の適正性（64GB 活用）
  - [ ] CPU 使用率の測定
  - [ ] バッチ処理効率

### 4.2 追加検証項目

- [ ] **ロバスト性の検証**

  - [ ] 照明変化への対応
  - [ ] ノイズ耐性の確認
  - [ ] 解像度変化への対応
  - [ ] フレームレート変化への対応

- [ ] **拡張性の検証**
  - [ ] 異なる動画フォーマットでの動作確認
  - [ ] マルチカメラ対応の可能性
  - [ ] クラウド処理の可能性
  - [ ] エッジデバイス対応の可能性

## 5. 出力・成果物

### 5.1 技術成果物

- [ ] **実装コード**

  - [ ] タイムスタンプ OCR モジュール
  - [ ] 時刻指定フレーム抽出モジュール
  - [ ] 人物検出モジュール（YOLOv11）
  - [ ] 統合パイプライン
  - [ ] 評価システム
  - [ ] ベンチマークツール
  - [ ] ユーティリティスクリプト

- [ ] **学習済みモデル・設定**
  - [ ] 最適化済み YOLOv11 モデル
  - [ ] OCR 前処理パラメータ
  - [ ] システム設定ファイル
  - [ ] 性能ベンチマーク記録

### 5.2 評価結果

- [ ] **精度評価レポート**

  - [ ] タイムスタンプ OCR 認識精度レポート（目標 99%以上）
  - [ ] フレーム抽出精度レポート（±10 秒以内）
  - [ ] 人物検出精度レポート（Precision, Recall, F1, mAP）
  - [ ] 定性的評価（目視確認結果）
  - [ ] エラーケース分析
  - [ ] 改善提案

- [ ] **性能評価レポート**
  - [ ] Apple M1 Max での処理速度ベンチマーク
  - [ ] メモリ使用量分析（64GB RAM 活用率）
  - [ ] スケーラビリティ評価
  - [ ] 最適化提案

### 5.3 文書化

- [ ] **技術ドキュメント**

  - [ ] システム設計書
  - [ ] API 仕様書
  - [ ] 実装詳細書
  - [ ] 使用方法ガイド

- [ ] **PoC 総括レポート**
  - [ ] 技術検証結果
  - [ ] 課題・制約事項
  - [ ] 次段階への提案
  - [ ] 実用化の可能性評価

## 6. リスク管理

### 6.1 技術的リスク

| リスク項目           | 影響度 | 発生確率 | 対策                                 | チェック |
| -------------------- | ------ | -------- | ------------------------------------ | -------- |
| モデル精度不足       | 高     | 中       | ファインチューニング、パラメータ調整 | [ ]      |
| 処理速度の遅延       | 中     | 低       | モデル軽量化、最適化                 | [ ]      |
| メモリ不足           | 中     | 低       | バッチサイズ調整、処理分割           | [ ]      |
| 依存ライブラリの問題 | 低     | 中       | バージョン固定、代替案準備           | [ ]      |

### 6.2 データ関連リスク

| リスク項目         | 影響度 | 発生確率 | 対策                         | チェック |
| ------------------ | ------ | -------- | ---------------------------- | -------- |
| 動画データの破損   | 高     | 低       | バックアップ作成、検証       | [ ]      |
| アノテーション品質 | 中     | 中       | 複数人チェック、品質基準策定 | [ ]      |
| データ不足         | 中     | 中       | 追加データ収集計画           | [ ]      |
| ラベリング間違い   | 低     | 中       | ダブルチェック体制           | [ ]      |

## 7. スケジュール

### 週次スケジュール

| 週      | 主要タスク                       | 成果物                       | チェック |
| ------- | -------------------------------- | ---------------------------- | -------- |
| 第 1 週 | 環境構築、データ前処理、基本実装 | 基本システム、サンプルデータ | [ ]      |
| 第 2 週 | 性能評価、最適化、最終検証       | 評価レポート、PoC 総括       | [ ]      |

### 日次詳細スケジュール

**第 1 週**

- [ ] **1 日目**: 環境構築、YOLOv11・OCR セットアップ
- [ ] **2 日目**: タイムスタンプ OCR システム実装
- [ ] **3 日目**: 時刻指定フレーム抽出システム実装
- [ ] **4 日目**: 人物検出システム実装（YOLOv11）
- [ ] **5 日目**: 各モジュールの単体テスト

**第 2 週**

- [ ] **6 日目**: システム統合・パイプライン構築
- [ ] **7 日目**: 精度評価システム実装
- [ ] **8 日目**: 性能評価、最適化
- [ ] **9 日目**: 最終検証、エンドツーエンドテスト
- [ ] **10 日目**: レポート作成、文書化

## 8. 最終チェックリスト

### 8.1 必須完了項目

- [x] タイムスタンプ OCR システムの実装完了
- [x] 5 分間隔フレーム抽出システムの実装完了
- [x] YOLOv11 による人物検出システムの実装完了
- [x] merged_moviefiles.mov での全処理完了
- [ ] タイムスタンプ認識精度（99%以上）の達成確認
- [x] フレーム抽出精度（±10 秒以内）の達成確認
- [ ] 人物検出精度（90%以上）の達成確認
- [ ] 評価レポートの作成完了

### 8.2 品質保証項目

- [x] コード品質チェック（可読性、保守性）
- [x] エラーハンドリングの実装確認
- [ ] ログ出力機能の動作確認
- [x] 異常系テストの実行
- [x] 文書化の完了確認

### 8.3 成果物確認

- [x] 全ソースコードのバージョン管理登録
- [x] 実行可能な状態での成果物提供
- [ ] 技術ドキュメントの完成
- [ ] PoC 総括レポートの完成
- [ ] 次段階への提案書作成

---

**改訂履歴**
| 版数 | 日付 | 改訂内容 | 作成者 |
|------|------|----------|--------|
| 1.0 | 2024-09-26 | 初版作成（人物検出 PoC 実装計画書） | AI Assistant |
| | | | |

**注記**: 本計画書は概念実証（PoC）段階に特化した内容であり、実用化段階では追加の要件定義、詳細設計、運用設計等が必要となります。
